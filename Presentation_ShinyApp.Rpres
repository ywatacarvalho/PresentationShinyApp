Simulating Sample Distribution for OLS Estimators - Developing Data Products Course
========================================================
author: Alexandre Xavier Ywata Carvalho, Ph.D.
date: September 21, 2014

Introduction
========================================================

- We created a simple application to demonstrate the behavior of the ordinary least squares (OLS) estimator, under different samples. 

- The user can choose the regression errors standard deviation, regression linear coefficient and regression angular coefficient. 

- It is possible to select the number of observations in each sample and the number of simulations. 

- The higher the number of simulations or the sample size, the more intensive the computations will be.

- Go to: https://simulationexamples.shinyapps.io/Deploy/


Simulated Regression Data
========================================================

- Simulating a regression sample data, with linear coefficient = 10, angular coefficient = 1.0, errors standard deviation = 4, and number of observations = 50

```{r, warning = FALSE, cache=TRUE, echo = FALSE, fig.width=10, fig.height=6}
beta0 <- 10; beta1 <- 1.0;
x <- rnorm(50, 10, 10); errors <- rnorm(50, 0, 4);
y <- beta0 + beta1 * x + errors;
            
par(mfrow = c(1,2));
par(mar = c(4,4,4,2));

plot(x, y, main = "Simulated Sample \n(One of the Samples)", col = 'blue', xlab="Predictive variable (x)", ylab = "Output variable (y)");
reg1 <- lm(y ~ x);
abline(reg1, col = 'red')

hist(errors, main = "Histogram of Residues \n(One of the Samples)", col = 'red', xlab = "Residues");  
```

Distribution for OLS Estimates
========================================================

- Simulating 100 samples, with 50 observations each, and estimated the coefficients using OLS -> we can analyze the behavior of the 100 estimates for both coefficients

```{r, warning = FALSE, cache=TRUE, echo = FALSE, fig.width=10, fig.height=6}
betas0_simul <- rep(0, 100);
betas1_simul <- rep(0, 100);

for (i in 1:100)
{
    beta0 <- 10; beta1 <- 1.0;
    x <- rnorm(50, 10, 10); errors <- rnorm(50, 0, 4);
    y <- beta0 + beta1 * x + errors;
    
    reg1 <- lm(y ~ x);
    coef <- reg1$coefficients;
    
    betas0_simul[i] <- as.numeric(coef[1]);
    betas1_simul[i] <- as.numeric(coef[2]);
}

par(mfrow = c(1,2));
par(mar = c(4,4,4,2));

hist(betas0_simul, main = "Histogram for Linear Coefficient \nEstimates", col = 'white', xlab = "Linear coef. estimates");     
lines(c(beta0,beta0), c(0,200), col = "red", lwd = 5);

hist(betas1_simul, main = "Histogram for Angular Coefficient \nEstimates", col = 'white', xlab = "Angular coef. estimates");    
lines(c(beta1,beta1), c(0,200), col = "red", lwd = 5);  
``` 


Conclusions
========================================================

- Simulations can be a powerful tool for teaching statistical concepts

- By using R, we can build reproducible codes and examples, enhancing students experience in learning statisics and econometrics

- Slidify and Shiny are wonderful tools to demonstrate the power and the usefuness of statistical tools

- We are certainly in the midst of revolutionary process of teaching and learning applied mathematical techniques 
